from datasets import load_dataset
import jsonlines

# åŠ è½½WikiAlignæ•°æ®é›†ï¼ˆå›½å†…é•œåƒï¼Œæ— éœ€ç¿»å¢™ï¼‰
dataset = load_dataset("wiki_align", split="train", trust_remote_code=True)

# è½¬æ¢ä¸ºALIGNSCOREè®ºæ–‡è¦æ±‚çš„æ ¼å¼
label_map = {1: "ALIGNED", 0: "CONTRADICT"}
paper_data = []
# å–1000æ¡ï¼ˆè¶³å¤ŸéªŒè¯æ•ˆæœï¼Œåç»­å¯æ‰©åˆ°1ä¸‡+ï¼‰
for item in dataset.select(range(1000)):
    paper_data.append({
        "text_a": item["sentence1"],
        "text_b": item["sentence2"],
        "label": label_map[item["label"]]
    })

# ä¿å­˜åˆ°dataç›®å½•ä¸‹
with jsonlines.open("data/train_paper.jsonl", "w") as f:
    f.write_all(paper_data)

print("âœ… è®ºæ–‡åŒæ¬¾æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼è·¯å¾„ï¼šdata/train_paper.jsonl")
print(f"ğŸ“Š æ•°æ®é›†è§„æ¨¡ï¼š{len(paper_data)}æ¡ï¼ŒåŒ…å«ALIGNED/CONTRADICTä¸¤ç±»æ ‡ç­¾")